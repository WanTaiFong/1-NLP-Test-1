{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3) CNN Test 1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_AwkFVJewqU",
        "colab_type": "code",
        "outputId": "9d81c0dc-01ef-4ff5-db0f-8deef4f641e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIxI-cAmN3BD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RAM workable at 25% rescaled\n",
        "rescaled_size = (216,384)\n",
        "input_shape = (None, 216, 384, 3)\n",
        "flatten_shape = (None, 82944, 3)\n",
        "threshold_for_results = 0.5\n",
        "# RAM exhausted at 50% rescaled\n",
        "#rescaled_size = (540,960)\n",
        "#input_shape = (None, 540, 960, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNYPhU0CCv_I",
        "colab_type": "code",
        "outputId": "f35724f3-5ac8-437a-f8ee-927fcc7d43e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# To ensure results can be repeated, the same seed value should be used for all testing\n",
        "seed_value= 2019\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(seed_value)\n",
        "# Additional seed value required to be set for tensorflow backend\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(seed_value)\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(seed_value)\n",
        "\n",
        "# 5. Configure a new global `tensorflow` session\n",
        "from keras import backend as K\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "print(\"Seed values re-set to 2019.\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed values re-set to 2019.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX13gBivoEuR",
        "colab_type": "code",
        "outputId": "0a4dbf79-9689-494d-c2be-1a7cf800cf05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# Imports to read images\n",
        "from matplotlib import pyplot as plt\n",
        "#from skimage import data\n",
        "from skimage.feature import blob_dog, blob_log, blob_doh\n",
        "from math import sqrt\n",
        "from skimage.color import rgb2gray\n",
        "import glob\n",
        "from skimage.io import imread\n",
        "print(\"Import Done\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Import Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZ7At8b3pma2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports for model building from tutorial site\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Slp9BBClQB1C",
        "colab_type": "code",
        "outputId": "93f8a12b-3f8d-4635-a74d-700f50486f71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# Imports from previous model building\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "#!pip install numpy==1.16.1\n",
        "import numpy as np\n",
        "\n",
        "from keras.datasets import imdb\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, GRU, Embedding\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "print(\"finish import\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "finish import\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJY_MuwHJOt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports for image downscaling because it takes too much RAM\n",
        "from skimage import data, color\n",
        "from skimage.transform import rescale, resize, downscale_local_mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGO6fi0XI8am",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test code for rescaling\n",
        "#image1 = image.load_img('/content/drive/My Drive/Colab Notebooks/3) CNN Test 1 Data/non-face (' +'123'+ ')' + '.png', grayscale=False, target_size = rescaled_size)\n",
        "#image1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFnq4Sd-qxI_",
        "colab_type": "code",
        "outputId": "8ceb03a3-99b2-4f45-cca7-e9fad1e7109d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Part 1/4 of data input\n",
        "# Read in the training images\n",
        "# There are only 324 pictures to train and validate\n",
        "# Separate 24 picture kept for testing\n",
        "# non-face (252)\n",
        "# 'non-face (' + i + ')' + '.png'\n",
        "\n",
        "train_image = []\n",
        "for i in tqdm(range(1,253)):\n",
        "    stringIndex = str(i)\n",
        "    img = image.load_img('/content/drive/My Drive/Colab Notebooks/3) CNN Test 1 Data/non-face (' + stringIndex + ')' + '.png', grayscale=False, target_size = rescaled_size)\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255 \n",
        "    train_image.append(img)\n",
        "\n",
        "print(len(train_image))\n",
        "#X = np.array(train_image) # wait for train face image below"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 252/252 [00:13<00:00, 17.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "252\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOEvOLfyoRgH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9bbe0f0c-12bd-459c-8983-b6ffba9d6ea1"
      },
      "source": [
        "# Part 2/4 of data input\n",
        "# Read in the training images\n",
        "# There are only 324 pictures to train and validate\n",
        "# Separate 24 picture kept for testing\n",
        "# face (72)\n",
        "# 'face (' + i + ')' + '.png'\n",
        "\n",
        "for i in tqdm(range(1,73)):\n",
        "    stringIndex = str(i)\n",
        "    img = image.load_img('/content/drive/My Drive/Colab Notebooks/3) CNN Test 1 Data/face (' + stringIndex + ')' + '.png', grayscale=False, target_size = rescaled_size)\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255 \n",
        "    train_image.append(img)\n",
        "\n",
        "print(len(train_image))\n",
        "X = np.array(train_image)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 72/72 [00:03<00:00, 18.39it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSmGI6ZO29l6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6e072bb8-dcd4-4a0a-a22c-c5afd730fed8"
      },
      "source": [
        "# Part 3/4 of data input\n",
        "# Read in the test images\n",
        "# Out of 24 test pictures, this half is non-face objects\n",
        "# test-empty (12)\n",
        "# 'test-empty (' + i + ')' + '.png'\n",
        "\n",
        "train_image = [] # Remove the training data\n",
        "for i in tqdm(range(1,13)):\n",
        "    stringIndex = str(i)\n",
        "    img = image.load_img('/content/drive/My Drive/Colab Notebooks/3) CNN Test 1 Data/test-empty (' + stringIndex + ')' + '.png', grayscale=False, target_size = rescaled_size)\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255 \n",
        "    train_image.append(img)\n",
        "\n",
        "print(len(train_image))\n",
        "#X_test = np.array(train_image)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 27.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRAe04PJ1iQ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f065ed8f-d8d3-414c-f2eb-1107fa854868"
      },
      "source": [
        "# Part 4/4 of data input\n",
        "# Read in the test images\n",
        "# Out of 24 test pictures, this half is face objects\n",
        "# test-face (12)\n",
        "# 'test-face (' + i + ')' + '.png'\n",
        "\n",
        "for i in tqdm(range(1,13)):\n",
        "    stringIndex = str(i)\n",
        "    img = image.load_img('/content/drive/My Drive/Colab Notebooks/3) CNN Test 1 Data/test-face (' + stringIndex + ')' + '.png', grayscale=False, target_size = rescaled_size)\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255 \n",
        "    train_image.append(img)\n",
        "\n",
        "print(len(train_image))\n",
        "X_test = np.array(train_image)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 30.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWLy6hHw57Yj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "220d2e3f-2d9f-40c7-93b7-94d37b6ea9e6"
      },
      "source": [
        "train_image = [] # Clear data\n",
        "\n",
        "print(X.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(324, 216, 384, 3)\n",
            "(24, 216, 384, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZbGOfD89SYL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "f0f6f1a8-7d9c-4116-d2c3-ac817dddc933"
      },
      "source": [
        "# Create y values for training data\n",
        "y = [0] * 252\n",
        "a = [1] * 72\n",
        "\n",
        "for i in a:\n",
        "  y.append(a[i])\n",
        "\n",
        "y = np.asarray(y)\n",
        "print(type(y))\n",
        "print(len(y)) # Total length should be 324 training data\n",
        "#y = to_categorical(y) # one hot encoding? but binary does not need, not multiclass\n",
        "\n",
        "print(y[251]) # Last of non-face\n",
        "print(y[252]) # First of face"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "324\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tXZXJSH_TG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "2e2fe00e-bb73-4755-af2d-0df655111e0d"
      },
      "source": [
        "# Create y values for test data\n",
        "y_test = [0] * 12\n",
        "a = [1] * 12\n",
        "\n",
        "for i in a:\n",
        "  y_test.append(a[i])\n",
        "\n",
        "y_test = np.asarray(y_test)\n",
        "print(type(y_test))\n",
        "print(len(y_test)) # Total length should be 324 training data\n",
        "#y = to_categorical(y) # one hot encoding? but binary does not need, not multiclass\n",
        "\n",
        "print(y_test[11]) # Last of non-face\n",
        "print(y_test[12]) # First of face"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "24\n",
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijz-0lTbAWjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=2019, test_size=0.2)\n",
        "X_train_flatten = X_train.reshape(259,82944,3)\n",
        "X_test_flatten = X_test.reshape(24,82944,3)\n",
        "X_val_flatten = X_val.reshape(65,82944,3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41_jSGGYfQGG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "edac2e08-35f5-46fa-8bf6-55c33f9b5266"
      },
      "source": [
        "np.random.shuffle(X_train)\n",
        "np.random.shuffle(X_train_flatten)\n",
        "np.random.shuffle(X_val)\n",
        "np.random.shuffle(X_val_flatten)\n",
        "print(\"Shuffled Training Data\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shuffled Training Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_db5yiFfAlUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "7f1cdd64-39b4-4f0b-c90f-f37cafc54cd9"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_train_flatten.shape)\n",
        "print(X_test_flatten.shape)\n",
        "print(X_val.shape)\n",
        "print(X_val_flatten.shape)\n",
        "print(len(y_train))\n",
        "print(len(y_val))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(259, 216, 384, 3)\n",
            "(259, 82944, 3)\n",
            "(24, 82944, 3)\n",
            "(65, 216, 384, 3)\n",
            "(65, 82944, 3)\n",
            "259\n",
            "65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ2ACwLICUMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###########################################################################################################################\n",
        "#------------------------------------------------------------Model Building-----------------------------------------------#\n",
        "###########################################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmNx1_wiC7HW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "8940a47e-d901-4637-dff2-4f00972a0998"
      },
      "source": [
        "# User defined parameters\n",
        "batch_size_user = 2\n",
        "epoch_user = 3\n",
        "\n",
        "print(\"User defined parameters set\")\n",
        "print(batch_size_user)\n",
        "print(epoch_user)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User defined parameters set\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WlySa7-Cdmi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "a94dad79-2804-486d-c29c-e83112b261af"
      },
      "source": [
        "## create the model\n",
        "model = 0\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# build for different input shape\n",
        "model.build(input_shape) # `input_shape` is the shape of the input data\n",
        "                         # e.g. input_shape = (None, 32, 32, 3)\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 248832)            0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 250)               62208250  \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 251       \n",
            "=================================================================\n",
            "Total params: 62,208,501\n",
            "Trainable params: 62,208,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKqfDcGXCrrR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "cea66e8f-8ef7-461d-b1d2-2af64a7ff2f8"
      },
      "source": [
        "# To ensure results can be repeated, the same seed value should be used for all testing\n",
        "seed_value= 2019\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(seed_value)\n",
        "# Additional seed value required to be set for tensorflow backend\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(seed_value)\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(seed_value)\n",
        "\n",
        "# 5. Configure a new global `tensorflow` session\n",
        "from keras import backend as K\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "print(\"Seed values re-set to 2019.\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed values re-set to 2019.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwXlPwKWCteV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "6e1bff6f-58a2-42e7-ca58-56faebb0fcaf"
      },
      "source": [
        "# Fit the model\n",
        "model.fit(X_train, y_train, epochs=epoch_user, batch_size=batch_size_user, validation_data = (X_val, y_val),verbose=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "Train on 259 samples, validate on 65 samples\n",
            "Epoch 1/3\n",
            "259/259 [==============================] - 12s 48ms/step - loss: 3.5523 - acc: 0.7761 - val_loss: 3.4716 - val_acc: 0.7846\n",
            "Epoch 2/3\n",
            "259/259 [==============================] - 11s 41ms/step - loss: 3.6095 - acc: 0.7761 - val_loss: 3.4716 - val_acc: 0.7846\n",
            "Epoch 3/3\n",
            "259/259 [==============================] - 11s 41ms/step - loss: 3.6095 - acc: 0.7761 - val_loss: 3.4716 - val_acc: 0.7846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ed86534e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X97gd6_vDF-g",
        "colab_type": "code",
        "outputId": "42616a1d-158c-43ad-de61-bf958dba0185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "# Test the model\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = y_pred.reshape(24)\n",
        "print(y_pred.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "avg = np.average(y_pred)\n",
        "print(\"Average value is: \", avg)\n",
        "\n",
        "y_pred[y_pred<avg] = 0\n",
        "y_pred[y_pred>=avg] = 1\n",
        "\n",
        "print(y_pred)\n",
        "print(y_test)\n",
        "totalsum = 0\n",
        "for i in range(y_test.size):\n",
        "  if(y_pred[i] == y_test[i]):\n",
        "    totalsum += 1\n",
        "\n",
        "print(totalsum / y_test.size * 100, \"%\")\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24,)\n",
            "(24,)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Average value is:  0.0\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "50.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIV3wIX2Pjkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###########################################################################################################################\n",
        "#------------------------------------------------------------Model 2-----------------------------------------------#\n",
        "###########################################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky-Z01fOPnzp",
        "colab_type": "code",
        "outputId": "f6865735-24e0-4ce5-af30-494afa3c009a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "# create the model\n",
        "model2 = 0\n",
        "model2 = Sequential()\n",
        "#model2.add(Flatten())\n",
        "#model2.add(GRU(units=64, input_shape=(125000000,1,1),return_sequences=True))\n",
        "#model2.add(GRU(units=32, return_sequences=True))\n",
        "#model2.add(GRU(units=16, return_sequences=True))\n",
        "#model2.add(GRU(units=8, return_sequences=True))\n",
        "model2.add(GRU(units=4, input_shape=(82944,3)))\n",
        "model2.add(Dense(1, activation='sigmoid'))\n",
        "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# build for different input shape\n",
        "model2.build(flatten_shape) # `input_shape` is the shape of the input data\n",
        "\n",
        "print(model2.summary())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_1 (GRU)                  (None, 4)                 96        \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 101\n",
            "Trainable params: 101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA7lmiDqQkbY",
        "colab_type": "code",
        "outputId": "760acbb1-3daf-45b8-eb6b-3b6105a76501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# To ensure results can be repeated, the same seed value should be used for all testing\n",
        "seed_value= 2019\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(seed_value)\n",
        "# Additional seed value required to be set for tensorflow backend\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(seed_value)\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(seed_value)\n",
        "\n",
        "# 5. Configure a new global `tensorflow` session\n",
        "from keras import backend as K\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "print(\"Seed values re-set to 2019.\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed values re-set to 2019.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-X8ihqpRQR6",
        "colab_type": "code",
        "outputId": "6a0af26c-5a47-422a-a29c-20535c3f3b73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "# Fit the model, using flatten X data\n",
        "model2.fit(X_train_flatten, y_train, epochs=epoch_user, batch_size=batch_size_user, validation_data = (X_val_flatten, y_val),verbose=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 259 samples, validate on 65 samples\n",
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-bcacb90900ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_flatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_val_flatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRuVSmIBRS2z",
        "colab_type": "code",
        "outputId": "c307158a-22f9-4f78-b7ed-3b9121cb0073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "# Test the model\n",
        "y_pred2 = model2.predict(X_test_flatten)\n",
        "y_pred2 = y_pred2.reshape(24)\n",
        "print(y_pred2.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "print(y_pred2)\n",
        "\n",
        "avg = np.average(y_pred2)\n",
        "print(\"Average value is: \", avg)\n",
        "\n",
        "y_pred2[y_pred2<avg] = 0\n",
        "y_pred2[y_pred2>=avg] = 1\n",
        "\n",
        "print(y_pred2)\n",
        "print(y_test)\n",
        "totalsum = 0\n",
        "for i in range(y_test.size):\n",
        "  if(y_pred2[i] == y_test[i]):\n",
        "    totalsum += 1\n",
        "\n",
        "print(totalsum / y_test.size * 100, \"%\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24,)\n",
            "(24,)\n",
            "[0.20313421 0.20934808 0.2688833  0.35604703 0.4071105  0.49826947\n",
            " 0.20044506 0.2027174  0.46728623 0.47548032 0.46889377 0.46986598\n",
            " 0.26180565 0.19449347 0.19394383 0.3768788  0.19559604 0.4869374\n",
            " 0.50380504 0.50380504 0.50380504 0.47407904 0.50380504 0.50380504]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1.]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "70.83333333333334 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9khRTL3dpyT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###########################################################################################################################\n",
        "#------------------------------------------------------------Model 3-----------------------------------------------#\n",
        "###########################################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgPVV07YoTG5",
        "colab_type": "code",
        "outputId": "6419faac-ec1b-4b69-c924-43bb16b20e97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "# create the model\n",
        "model3 = 0\n",
        "model3 = Sequential()\n",
        "model3.add(Conv1D(filters=16, kernel_size=5, padding='same', activation='relu'))\n",
        "model3.add(MaxPooling1D(pool_size=2))\n",
        "model3.add(Flatten())\n",
        "model3.add(Dense(1, activation='sigmoid'))\n",
        "model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# build for different input shape\n",
        "model3.build(flatten_shape) # `input_shape` is the shape of the input data\n",
        "\n",
        "print(model3.summary())"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_1 (Conv1D)            (None, 82944, 16)         256       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 41472, 16)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 663552)            0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 663553    \n",
            "=================================================================\n",
            "Total params: 663,809\n",
            "Trainable params: 663,809\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rj_UFkLmpNvJ",
        "colab_type": "code",
        "outputId": "eece9e5f-412a-4df9-ddca-c57995a31a6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# To ensure results can be repeated, the same seed value should be used for all testing\n",
        "seed_value= 2019\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(seed_value)\n",
        "# Additional seed value required to be set for tensorflow backend\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(seed_value)\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(seed_value)\n",
        "\n",
        "# 5. Configure a new global `tensorflow` session\n",
        "from keras import backend as K\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "print(\"Seed values re-set to 2019.\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed values re-set to 2019.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsWZP_EqpRai",
        "colab_type": "code",
        "outputId": "c57b41be-9fe5-484c-e546-d2fcb0dec79b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "# Fit the model, using flatten X data\n",
        "model3.fit(X_train_flatten, y_train, epochs=epoch_user, batch_size=batch_size_user, validation_data = (X_val_flatten, y_val),verbose=1)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 259 samples, validate on 65 samples\n",
            "Epoch 1/3\n",
            "259/259 [==============================] - 4s 15ms/step - loss: 3.6279 - acc: 0.7683 - val_loss: 3.4716 - val_acc: 0.7846\n",
            "Epoch 2/3\n",
            "259/259 [==============================] - 3s 11ms/step - loss: 3.6095 - acc: 0.7761 - val_loss: 3.4716 - val_acc: 0.7846\n",
            "Epoch 3/3\n",
            "259/259 [==============================] - 3s 11ms/step - loss: 3.6095 - acc: 0.7761 - val_loss: 3.4716 - val_acc: 0.7846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ed7832f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJQM2dWRqiho",
        "colab_type": "code",
        "outputId": "ac214420-0423-47a6-b915-6ab4f99833bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "source": [
        "# Test the model\n",
        "y_pred3 = model3.predict(X_test_flatten)\n",
        "y_pred3 = y_pred3.reshape(24)\n",
        "print(y_pred3.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "print(y_pred3)\n",
        "\n",
        "avg = np.average(y_pred3)\n",
        "print(\"Average value is: \", avg)\n",
        "\n",
        "y_pred3[y_pred3<=avg] = 0\n",
        "y_pred3[y_pred3>avg] = 1\n",
        "\n",
        "print(y_pred3)\n",
        "print(y_test)\n",
        "totalsum = 0\n",
        "for i in range(y_test.size):\n",
        "  if(y_pred3[i] == y_test[i]):\n",
        "    totalsum += 1\n",
        "\n",
        "print(totalsum / y_test.size * 100, \"%\")\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24,)\n",
            "(24,)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "Average value is:  0.0\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "50.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_bJyhwhdrrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###########################################################################################################################\n",
        "#------------------------------------------------------------Model 4-----------------------------------------------#\n",
        "###########################################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5lPrOTtrh6o",
        "colab_type": "code",
        "outputId": "f0a9f5e4-8815-45c5-b8b9-0e00e8ac8edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        }
      },
      "source": [
        "# create the model\n",
        "model4 = 0\n",
        "model4 = Sequential()\n",
        "model4.add(Conv2D(16, kernel_size=(5, 5),activation='relu'))\n",
        "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model4.add(Flatten())\n",
        "model4.add(Dense(1, activation='sigmoid'))\n",
        "model4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# build for different input shape\n",
        "model4.build(input_shape) # `input_shape` is the shape of the input data\n",
        "\n",
        "print(model4.summary())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 212, 380, 16)      1216      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 106, 190, 16)      0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 322240)            0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 322241    \n",
            "=================================================================\n",
            "Total params: 323,457\n",
            "Trainable params: 323,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPRjNEJFsgxY",
        "colab_type": "code",
        "outputId": "872e5f8f-a12d-4fdf-ecd2-af7c99835ade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# To ensure results can be repeated, the same seed value should be used for all testing\n",
        "seed_value= 2019\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(seed_value)\n",
        "# Additional seed value required to be set for tensorflow backend\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(seed_value)\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(seed_value)\n",
        "\n",
        "# 5. Configure a new global `tensorflow` session\n",
        "from keras import backend as K\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "print(\"Seed values re-set to 2019.\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed values re-set to 2019.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhGEZneCskK4",
        "colab_type": "code",
        "outputId": "d82ccb03-71c9-4c72-8120-0445e8227a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "# Fit the model\n",
        "model4.fit(X_train, y_train, epochs=epoch_user, batch_size=batch_size_user, validation_data = (X_val, y_val),verbose=1)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 259 samples, validate on 65 samples\n",
            "Epoch 1/3\n",
            "259/259 [==============================] - 3s 10ms/step - loss: 3.5529 - acc: 0.7761 - val_loss: 3.4716 - val_acc: 0.7846\n",
            "Epoch 2/3\n",
            "259/259 [==============================] - 2s 8ms/step - loss: 3.6095 - acc: 0.7761 - val_loss: 3.4716 - val_acc: 0.7846\n",
            "Epoch 3/3\n",
            "259/259 [==============================] - 2s 8ms/step - loss: 3.6095 - acc: 0.7761 - val_loss: 3.4716 - val_acc: 0.7846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ed5b86240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKAz46nEso_n",
        "colab_type": "code",
        "outputId": "bc76aae6-2eac-429c-976e-c20f231537db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "# Test the model\n",
        "y_pred4 = model4.predict(X_test)\n",
        "y_pred4= y_pred4.reshape(24)\n",
        "print(y_pred4.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "print(y_pred4)\n",
        "\n",
        "avg = np.average(y_pred4)\n",
        "print(\"Average value is: \", avg)\n",
        "\n",
        "y_pred4[y_pred4<=avg] = 0\n",
        "y_pred4[y_pred4>avg] = 1\n",
        "\n",
        "print(y_pred4)\n",
        "print(y_test)\n",
        "totalsum = 0\n",
        "for i in range(y_test.size):\n",
        "  if(y_pred4[i] == y_test[i]):\n",
        "    totalsum += 1\n",
        "\n",
        "print(totalsum / y_test.size * 100, \"%\")\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FailedPreconditionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-6eebd9c41eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_pred4\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0my_pred4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value dense_5/bias\n\t [[{{node dense_5/bias/read}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LE6V87OdtR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###########################################################################################################################\n",
        "#------------------------------------------------------------Model 5-----------------------------------------------#\n",
        "###########################################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxz8wYEx5vDv",
        "colab_type": "code",
        "outputId": "b7752c21-b2a0-4548-84a2-b8e19ff1e778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "source": [
        "# create the model\n",
        "model5 = 0\n",
        "model5 = Sequential()\n",
        "model5.add(Conv2D(16, kernel_size=(5, 5),activation='relu'))\n",
        "model5.add(Conv2D(8, (5, 5), activation='relu'))\n",
        "model5.add(Conv2D(4, (5, 5), activation='relu'))\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model5.add(Flatten())\n",
        "model5.add(Dense(1, activation='sigmoid'))\n",
        "model5.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# build for different input shape\n",
        "model5.build(input_shape) # `input_shape` is the shape of the input data\n",
        "\n",
        "print(model5.summary())"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_39 (Conv2D)           (None, 212, 380, 16)      1216      \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 208, 376, 8)       3208      \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 204, 372, 4)       804       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 102, 186, 4)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 51, 93, 4)         0         \n",
            "_________________________________________________________________\n",
            "flatten_17 (Flatten)         (None, 18972)             0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 1)                 18973     \n",
            "=================================================================\n",
            "Total params: 24,201\n",
            "Trainable params: 24,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adlQKQ_k6wij",
        "colab_type": "code",
        "outputId": "8c0dfdc7-11dc-4300-a313-3ee93a606e10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "# To ensure results can be repeated, the same seed value should be used for all testing\n",
        "seed_value= 2019\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(seed_value)\n",
        "# Additional seed value required to be set for tensorflow backend\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(seed_value)\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(seed_value)\n",
        "\n",
        "# 5. Configure a new global `tensorflow` session\n",
        "from keras import backend as K\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "K.set_session(sess)\n",
        "\n",
        "print(\"Seed values re-set to 2019.\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed values re-set to 2019.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxiFptZE6yAj",
        "colab_type": "code",
        "outputId": "f17a545d-c931-4ebb-c4d6-272be6bf0bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        }
      },
      "source": [
        "# Fit the model\n",
        "model5.fit(X_train, y_train, epochs=epoch_user, batch_size=batch_size_user, validation_data = (X_val, y_val),verbose=1)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 259 samples, validate on 65 samples\n",
            "Epoch 1/3\n",
            "259/259 [==============================] - 5s 18ms/step - loss: 0.6833 - acc: 0.7568 - val_loss: 0.6178 - val_acc: 0.7846\n",
            "Epoch 2/3\n",
            "259/259 [==============================] - 3s 12ms/step - loss: 0.5578 - acc: 0.7761 - val_loss: 0.5237 - val_acc: 0.7846\n",
            "Epoch 3/3\n",
            "259/259 [==============================] - 3s 12ms/step - loss: 0.5388 - acc: 0.7761 - val_loss: 0.5291 - val_acc: 0.7846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3ebc26fe10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JWwbBLZ6zzi",
        "colab_type": "code",
        "outputId": "fab3d8bc-7efe-4565-f5be-571a93f25c27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Test the model\n",
        "y_pred5 = model5.predict(X_test)\n",
        "y_pred5= y_pred5.reshape(24)\n",
        "print(y_pred5.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "print(y_pred5)\n",
        "\n",
        "avg = np.average(y_pred5)\n",
        "print(\"Average value is: \", avg)\n",
        "\n",
        "y_pred5[y_pred5<=avg] = 0\n",
        "y_pred5[y_pred5>avg] = 1\n",
        "\n",
        "print(y_pred5)\n",
        "print(y_test)\n",
        "totalsum = 0\n",
        "for i in range(y_test.size):\n",
        "  if(y_pred5[i] == y_test[i]):\n",
        "    totalsum += 1\n",
        "\n",
        "print(totalsum / y_test.size * 100, \"%\")\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(24,)\n",
            "(24,)\n",
            "[0.13395968 0.14205521 0.14006689 0.1490475  0.1389358  0.1339513\n",
            " 0.15017414 0.14548627 0.13809803 0.13555998 0.1361064  0.13291919\n",
            " 0.1662134  0.16550967 0.1592584  0.1673224  0.16147569 0.16743457\n",
            " 0.16799292 0.16642398 0.16372967 0.15803534 0.15980673 0.16090003]\n",
            "Average value is:  0.15168597\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "100.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}